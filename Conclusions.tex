\section{Conclusions}

	\begin{itemize}
		\item As we proposed since the beginning, there are several factors that affects the price of a particular stock, besides the most common one: \emph{supply and demmand}, our initial position and the most natural was that the positive news are positively correlated with the positive increments of the stock and vice-versa, the negative news are positively correlated with the drops in the stock prices; and as we could see in the results section, this is not entirely true according to the acquired data, it could happen as well that some companies have negative news and its price will go up.
		\item At the beginning what we tried to achieve was some numerical correlation by accounting qualitative factors, here came to play the news articles. This articles could have positive or negative polarity and somehow, according to our initial position, and to the data obtained we can say that in most of cases the companies has almost same correlation in positive and negative articles; usually negative, which states that only by publishing news for a company that follows this pattern, means that the stock price may not improve significantly, indeed, sometimes it could go down.
		\item Most of the work that we are doing here is about to structure information that does not have a particular, uniform or homogeneous structure. So, according to the processed information, it is shown once again that this is a particularly difficult and time consuming task: \emph{to automatise the retrieval of unstructured information}. In our case this happen because every Web page has different structure.
		\item Web 2.0 plays an important role in this work; because it allows users to interact and collaborate as creators of content. In our case, this work was possible to developed because by these days we have the appropriate tools and the availability of the data to do a research like this. In our case the content creators are every reporter that works for a News Portal writing articles.
		\item It is strongly recommended for Web Crawlers to implement \emph{Parallelism}. Because the CPU while is waiting for downloading a Web Page or performing I/O operations, is wasting a lot of CPU cycles that could be used by another thread in order to do some useful computation.
	\end{itemize}

\section{Future work}

In this section, we will mention some useful directives for the future work regarding this work. 

In the \emph{"previous work"} section (\ref{previousResults}), one limitation was the number of articles; in our case as mentioned in the results section (\ref{ExperimentalResults1}) we retrieve more than 15,000 articles for the 36 companies in one month. So it would be worth to get one more level of detail by trying to get the \emph{published time} of the articles and perform a \emph{real-time analysis} with the stock prices.

Besides, we can apply more advanced statistical methods in order to analyse the causality of the events. For this we recommend the ARMA Models which stands for autoregressiveâ€“moving-average (ARMA) models.

As we know, heuristics are basically experienced-based techniques for problem solving. In our case we applied heuristics to try to extract a news article from a host that we haven't construct its locator (section \ref{locators}); to this heuristic technique in our work we called it \emph{Generic Locator}, and as a future work would be worth to try to improve this algorithm in order to \emph{increase} the rate of extracted news articles.

Finally, the last directive would be to consider the implementation of the Web 3.0 (Semantic Web) in the articles we retrieve. In order not only to classify the polarity of the article but to relate the information contained in the article with the web of data.